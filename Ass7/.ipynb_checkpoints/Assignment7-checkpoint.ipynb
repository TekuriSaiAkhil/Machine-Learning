{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1705ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Start of Assignment 7\n",
    "## Name: Tekuri Sai Akhil\n",
    "## NetId: st5050"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7373ed48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc08dd26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "231acead",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('DataSetForPhishingVSBenignUrl.csv')\n",
    "df = df.loc[df['URL_Type_obf_Type'].isin(['benign','phishing'])]\n",
    "df = df.drop_duplicates()\n",
    "df = df.dropna() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a46bd078",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = df.columns[:-1]\n",
    "X = np.array(df.drop(['URL_Type_obf_Type'], axis=1))\n",
    "Y = np.array(df['URL_Type_obf_Type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a29220a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2338c5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "depths = [1,3,6,9,12,15,18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f00fb2a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gini criterion:\n",
      "    For depth = 1 (train_score, test_score) = (0.970378919022889, 0.9653846153846154)\n",
      "    For depth = 3 (train_score, test_score) = (1.0, 0.9730769230769231)\n",
      "    For depth = 6 (train_score, test_score) = (1.0, 0.9769230769230769)\n",
      "    For depth = 9 (train_score, test_score) = (1.0, 0.9753846153846154)\n",
      "    For depth = 12 (train_score, test_score) = (1.0, 0.9730769230769231)\n",
      "    For depth = 15 (train_score, test_score) = (1.0, 0.9746153846153847)\n",
      "    For depth = 18 (train_score, test_score) = (1.0, 0.9515384615384616)\n"
     ]
    }
   ],
   "source": [
    "print(\"Gini criterion:\")\n",
    "for depth in depths:\n",
    "    tree_gini = DecisionTreeClassifier(criterion='gini',max_depth=depth)\n",
    "    abc = AdaBoostClassifier(base_estimator=tree_gini,random_state=0).fit(X_train, Y_train)\n",
    "    train_score = abc.score(X_train, Y_train)\n",
    "    test_score = abc.score(X_test, Y_test)\n",
    "    print(\"    For depth = \"+str(depth)+\" (train_score, test_score) = \"+\"(\"+str(train_score)+\", \"+str(test_score)+\")\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5fe5239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy criterion:\n",
      "    For depth = 1 (train_score, test_score) = (0.9701865743412195, 0.9646153846153847)\n",
      "    For depth = 3 (train_score, test_score) = (1.0, 0.9715384615384616)\n",
      "    For depth = 6 (train_score, test_score) = (1.0, 0.9723076923076923)\n",
      "    For depth = 9 (train_score, test_score) = (1.0, 0.9723076923076923)\n",
      "    For depth = 12 (train_score, test_score) = (1.0, 0.9776923076923076)\n",
      "    For depth = 15 (train_score, test_score) = (1.0, 0.9507692307692308)\n",
      "    For depth = 18 (train_score, test_score) = (1.0, 0.9592307692307692)\n"
     ]
    }
   ],
   "source": [
    "print(\"Entropy criterion:\")\n",
    "for depth in depths:\n",
    "    tree_entropy = DecisionTreeClassifier(criterion='entropy',max_depth=depth)\n",
    "    abc = AdaBoostClassifier(base_estimator=tree_entropy,random_state=0).fit(X_train, Y_train)\n",
    "    train_score = abc.score(X_train, Y_train)\n",
    "    test_score = abc.score(X_test, Y_test)\n",
    "    print(\"    For depth = \"+str(depth)+\" (train_score, test_score) = \"+\"(\"+str(train_score)+\", \"+str(test_score)+\")\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d9426835",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) When using AdaBoost Classifier even for small value of depths = (1,3), we got very high accuracy on both train and test data compared to Scikit Decision Tree Classifier\n",
      "2) Improvement in accuracies compared to Scikit Decision Tree Classifier is beacuse AdaBoost Classifier uses ensemble method to produce sequence of weak classifiers and combining them to produce strong classifer\n",
      "3) When using adaboost classifier, in both the cases(criterion = 'gini' or 'entropy'), as depth increases we can observe that the model overfits\n",
      "4) As the depth increases from 1 to 6 both train and test accuracies increases\n",
      "5) As the depth increases from 6 to 18 the train accuracy is 1(maximum value) but the test accuracy decreases indication overfitting\n",
      "6) This is expected because in decision tree are prone to overfitting as the depth of the tree increases\n"
     ]
    }
   ],
   "source": [
    "print(\"1) When using AdaBoost Classifier even for small value of depths = (1,3), we got very high accuracy on both train and test data compared to Scikit Decision Tree Classifier\")\n",
    "print(\"2) Improvement in accuracies compared to Scikit Decision Tree Classifier is beacuse AdaBoost Classifier uses ensemble method to produce sequence of weak classifiers and combining them to produce strong classifer\")\n",
    "print(\"3) When using adaboost classifier, in both the cases(criterion = 'gini' or 'entropy'), as depth increases we can observe that the model overfits\")\n",
    "print(\"4) As the depth increases from 1 to 6 both train and test accuracies increases\")\n",
    "print(\"5) As the depth increases from 6 to 18 the train accuracy is 1(maximum value) but the test accuracy decreases indication overfitting\")\n",
    "print(\"6) This is expected because in decision tree are prone to overfitting as the depth of the tree increases\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4dc5984f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## End of Assignment 7"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
